{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from konlpy.tag import Twitter\n",
    "from nltk.corpus import stopwords\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_excel(\n",
    "    \"/Users/shinjongho/Desktop/2023_ISF_분석/ISF-Analysis/news_data/ISF_news.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "re_title = []   # symbol remove [title1, title2, ... , title10]\n",
    "pt_title = []\n",
    "result_list = []    # find NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_all =\"\"\n",
    "for line in file['content']:\n",
    "    text_all += line\n",
    "\n",
    "okt = Okt()\n",
    "noun = okt.nouns(text_all)\n",
    "\n",
    "for i,v in enumerate(noun) :\n",
    "    if len(v)<2:\n",
    "        noun.pop(i)\n",
    "\n",
    "counts = Counter(noun)\n",
    "kor = counts.most_common()\n",
    "\n",
    "#print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "NN_words = []\n",
    "nlpy = Twitter()\n",
    "\n",
    "change = re.sub(\"[^,.?!\\w\\s]\", \"\", text_all)\n",
    "token = nltk.word_tokenize(change.lower())\n",
    "pt = nltk.pos_tag(token)\n",
    "\n",
    "for w, p in pt:\n",
    "    if \"NN\" in p and w.encode().isalpha() or \"NNP\" in p and w.encode().isalpha():\n",
    "        NN_words.append(w)\n",
    "\n",
    "wlem = nltk.WordNetLemmatizer()\n",
    "lemmatized_words = []\n",
    "\n",
    "for word in NN_words:\n",
    "    new_word = wlem.lemmatize(word)\n",
    "    lemmatized_words.append(new_word)\n",
    "\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "unique_NN_words = set(lemmatized_words)\n",
    "final_NN_words = lemmatized_words\n",
    "\n",
    "for word in unique_NN_words:\n",
    "    if word in stopwords_list:\n",
    "        while word in final_NN_words:\n",
    "            final_NN_words.remove(word)\n",
    "\n",
    "counts = Counter(final_NN_words)\n",
    "eng = counts.most_common()\n",
    "\n",
    "# print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = kor + eng\n",
    "\n",
    "value.sort(key=lambda x: -x[1])\n",
    "\n",
    "df = pd.DataFrame(value, columns=[\"키워수\", \"개수\"])\n",
    "df.to_excel(\n",
    "    f\"/Users/shinjongho/Desktop/2023_ISF_분석/ISF-Analysis/completed_data/주제 2) 2023_국제스포츠_주요_키워드_분석/ISF_주요_키워드_분석.xlsx\",\n",
    "    sheet_name=\"data_01\",\n",
    ")\n",
    "\n",
    "# print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
